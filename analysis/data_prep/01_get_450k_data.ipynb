{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gdc(\n",
    "    samples,\n",
    "    data_type=\"Methylation Beta Value\",\n",
    "    platform=\"Illumina Human Methylation 450\",\n",
    "):\n",
    "\n",
    "    base_url = \"https://api.gdc.cancer.gov/files\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # Define filters for the query\n",
    "    filters = {\n",
    "        \"op\": \"and\",\n",
    "        \"content\": [\n",
    "            {\"op\": \"in\", \"content\": {\"field\": \"cases.submitter_id\", \"value\": samples}},\n",
    "            {\n",
    "                \"op\": \"in\",\n",
    "                \"content\": {\"field\": \"data_category\", \"value\": [\"DNA Methylation\"]},\n",
    "            },\n",
    "            {\"op\": \"in\", \"content\": {\"field\": \"data_type\", \"value\": [data_type]}},\n",
    "            {\"op\": \"in\", \"content\": {\"field\": \"platform\", \"value\": [platform]}},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Define API query parameters\n",
    "    params = {\n",
    "        \"filters\": json.dumps(filters),\n",
    "        \"fields\": \"file_id,file_name\",\n",
    "        \"format\": \"JSON\",\n",
    "        \"size\": \"1000\",\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()[\"data\"][\"hits\"]\n",
    "        file_ids = [result[\"file_id\"] for result in results]\n",
    "        return file_ids\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"API request failed with status code {response.status_code}: {response.text}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files_batch(file_ids, output_dir=\"downloads\"):\n",
    "    data_endpt = \"https://api.gdc.cancer.gov/data\"\n",
    "\n",
    "    ids = file_ids\n",
    "\n",
    "    params = {\"ids\": ids}\n",
    "\n",
    "    response = requests.post(\n",
    "        data_endpt, data=json.dumps(params), headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "\n",
    "    response_head_cd = response.headers[\"Content-Disposition\"]\n",
    "\n",
    "    file_name = output_dir + \"/\" + re.findall(\"filename=(.+)\", response_head_cd)[0]\n",
    "\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "\n",
    "    with open(file_name, \"wb\") as output_file:\n",
    "        output_file.write(response.content)\n",
    "    \n",
    "    if file_name.endswith(\".tar.gz\"):\n",
    "        with tarfile.open(file_name, \"r:gz\") as tar:\n",
    "            tar.extractall(path=os.path.dirname(file_name))\n",
    "        # print(f\"Extracted {file_name} to {os.path.dirname(file_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(file_ids):\n",
    "    metadata_endpoint = \"https://api.gdc.cancer.gov/files\"\n",
    "    params = {\n",
    "        \"filters\": {\"op\": \"in\", \"content\": {\"field\": \"file_id\", \"value\": file_ids}},\n",
    "        \"fields\": \"file_id,file_name,cases.samples.sample_type,cases.project.project_id,cases.case_id,cases.submitter_id,cases.samples.sample_id,cases.samples.submitter_id\",  # Added case details\n",
    "        \"format\": \"JSON\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        metadata_endpoint,\n",
    "        data=json.dumps(params),\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"data\"][\"hits\"]\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Failed to fetch metadata: {response.status_code} - {response.text}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def flatten_metadata(metadata):\n",
    "    flattened = {}\n",
    "\n",
    "    def flatten_helper(d, parent_key=\"\"):\n",
    "        \"\"\"Helper function to flatten nested structures.\"\"\"\n",
    "        if isinstance(d, dict):\n",
    "            for k, v in d.items():\n",
    "                new_key = f\"{parent_key}__{k}\" if parent_key else k\n",
    "                flatten_helper(v, new_key)\n",
    "        elif isinstance(d, list):\n",
    "            if d:  # Ensure list is not empty\n",
    "                flatten_helper(d[0], parent_key)  # Assuming only 1 item per list\n",
    "        else:\n",
    "            flattened[parent_key] = d\n",
    "\n",
    "    flatten_helper(metadata)\n",
    "    return flattened\n",
    "\n",
    "\n",
    "def save_metadata_to_csv(metadata, metadata_file=\"downloads/metadata.csv\"):\n",
    "    flattened_metadata = [flatten_metadata(file_meta) for file_meta in metadata]\n",
    "\n",
    "    headers = list(flattened_metadata[0].keys())\n",
    "\n",
    "    file_exists = os.path.exists(metadata_file)\n",
    "\n",
    "    with open(metadata_file, mode=\"a\" if file_exists else \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=headers)\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        writer.writerows(flattened_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meth_data = cancer_methylation = pd.read_csv(\n",
    "    \"/uufs/chpc.utah.edu/common/home/u0914269/clement/projects/20230828_tcga_methylation/side_projects/20232110_TCGA_METHYLATION_CLINICAL_ML/data/methylation/hm27_hm450_merge_meth_data.tsv\",\n",
    "    sep=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2583"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = list(meth_data.columns[4:])\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = [sample[:-3] for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2555 files to download.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from http.client import RemoteDisconnected\n",
    "\n",
    "file_ids = []\n",
    "batch_size = 100\n",
    "max_retries = 5\n",
    "retry_wait_time = 1\n",
    "\n",
    "for i in range(0, len(sample_ids), batch_size):\n",
    "    batch_samples = sample_ids[i : i + batch_size]\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            batch_file_ids = query_gdc(batch_samples)\n",
    "            file_ids += batch_file_ids\n",
    "            break\n",
    "        except RemoteDisconnected:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                raise Exception(\"Too many retries, failed to query GDC.\")\n",
    "            time.sleep(retry_wait_time)\n",
    "            retry_wait_time = retry_wait_time * 5\n",
    "            if retry_wait_time > 300:\n",
    "                retries = max_retries\n",
    "                raise Exception(\"Too many retries, failed to query GDC.\")\n",
    "print(f\"Found {len(file_ids)} files to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered file_ids, 0 files remaining to download.\n"
     ]
    }
   ],
   "source": [
    "existing_folders = [folder for folder in os.listdir(\"downloads\") if os.path.isdir(os.path.join(\"downloads\", folder))]\n",
    "download_file_ids = [file_id for file_id in file_ids if file_id not in existing_folders]\n",
    "print(f\"Filtered file_ids, {len(download_file_ids)} files remaining to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_wait_time = 1\n",
    "max_retries = 5\n",
    "for i in range(0, len(download_file_ids), batch_size):\n",
    "    batch_file_ids = download_file_ids[i : i + batch_size]\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            download_files_batch(batch_file_ids)\n",
    "            break\n",
    "        except RemoteDisconnected:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                raise Exception(\"Too many retries, failed to download files.\")\n",
    "            time.sleep(retry_wait_time)\n",
    "            retry_wait_time = retry_wait_time * 5\n",
    "            if retry_wait_time > 300:\n",
    "                retries = max_retries\n",
    "                raise Exception(\"Too many retries, failed to download files.\")\n",
    "    time.sleep(300)  # Sleep for 5 minutes to avoid rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file does not exist.\n"
     ]
    }
   ],
   "source": [
    "metadata_file = \"downloads/metadata.csv\"\n",
    "\n",
    "if os.path.exists(metadata_file):\n",
    "    existing_metadata = pd.read_csv(metadata_file)\n",
    "    existing_file_ids = existing_metadata[\"file_id\"].tolist()\n",
    "    needed_meta_file_ids = [\n",
    "        file_id for file_id in file_ids if file_id not in existing_file_ids\n",
    "    ]\n",
    "    print(f\"Filtered file_ids, {len(needed_meta_file_ids)} files remaining to download.\")\n",
    "else:\n",
    "    needed_meta_file_ids = file_ids\n",
    "    print(\"Metadata file does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_wait_time = 1\n",
    "max_retries = 10\n",
    "batch_size = 10\n",
    "for i in range(0, len(needed_meta_file_ids), batch_size):\n",
    "    batch_file_ids = needed_meta_file_ids[i : i + batch_size]\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            meta_data = get_metadata(batch_file_ids)\n",
    "            save_metadata_to_csv(meta_data)\n",
    "            break\n",
    "        except RemoteDisconnected:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                raise Exception(\"Too many retries, failed to download files.\")\n",
    "            time.sleep(retry_wait_time)\n",
    "            retry_wait_time = retry_wait_time * 5\n",
    "            if retry_wait_time > 300:\n",
    "                retries = max_retries\n",
    "                raise Exception(\"Too many retries, failed to download files.\")\n",
    "    time.sleep(5)  # Sleep for 5 sec to avoid rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jt_methylation_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
